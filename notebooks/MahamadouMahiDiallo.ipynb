{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Data Wrangling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Imports\n",
    "import glob\n",
    "import shutil\n",
    "from pathlib import Path\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import random\n",
    "\n",
    "import kagglehub\n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras import layers, Sequential\n",
    "\n",
    "import shutil\n",
    "\n",
    "import pandas as pd\n",
    "from collections import Counter"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Data Download"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Download latest version\n",
    "path = kagglehub.dataset_download(\"paultimothymooney/breast-histopathology-images\")\n",
    "\n",
    "print(\"Path to dataset files:\", path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2. Data re-structuring"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Right now, the data exists in a set of numbered directories, one for each patient. In each patient directory there are two sub-directories 0 and 1 containing IDC negative and IDC positive images. We need to collect all of the IDC negative images and IDC positive images into their own directories."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get a list of patient directories\n",
    "patients=glob.glob(f'{path}/*')\n",
    "\n",
    "# Set up target directories for file copy\n",
    "idc_negative_directory='../data/idc_negative/'\n",
    "idc_positive_directory='../data/idc_positive/'\n",
    "\n",
    "Path(idc_negative_directory).mkdir(parents=True, exist_ok=True)\n",
    "Path(idc_positive_directory).mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "# Loop on the patient directories and copy the '0' images to\n",
    "# the idc_negative directory and the '1' images to the\n",
    "# idc_positive directory\n",
    "for patient in patients:\n",
    "\n",
    "    # Copy the idc negative images from this patient\n",
    "    idc_negative_images=glob.glob(f'{patient}/0/*.png')\n",
    "\n",
    "    for image in idc_negative_images:\n",
    "        shutil.copy(image, idc_negative_directory)\n",
    "\n",
    "    # Copy the idc positive images from this patient\n",
    "    idc_positive_images=glob.glob(f'{patient}/1/*.png')\n",
    "\n",
    "    for image in idc_positive_images:\n",
    "        shutil.copy(image, idc_positive_directory)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 1b: Data Sampling for Efficiency\n",
    "sampled_negative_directory = '../data_sampled/idc_negative/'\n",
    "sampled_positive_directory = '../data_sampled/idc_positive/'\n",
    "\n",
    "# Create directories for sampled data\n",
    "Path(sampled_negative_directory).mkdir(parents=True, exist_ok=True)\n",
    "Path(sampled_positive_directory).mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "# Sampling parameters\n",
    "sample_size = 100  # Adjust as needed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to sample and copy images\n",
    "def sample_images(source_dir, target_dir, sample_size):\n",
    "    images = glob.glob(f'{source_dir}/*.png')\n",
    "    sampled_images = random.sample(images, min(sample_size, len(images)))\n",
    "    for image in sampled_images:\n",
    "        shutil.copy(image, target_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sample negative and positive images\n",
    "sample_images(idc_negative_directory, sampled_negative_directory, sample_size)\n",
    "sample_images(idc_positive_directory, sampled_positive_directory, sample_size)\n",
    "\n",
    "print(\"Sampling complete!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "EDA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "idc_negative_count = len(glob.glob(f'{idc_negative_directory}/*.png'))\n",
    "idc_positive_count = len(glob.glob(f'{idc_positive_directory}/*.png'))\n",
    "\n",
    "print(f\"IDC Negative Images: {idc_negative_count}\")\n",
    "print(f\"IDC Positive Images: {idc_positive_count}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.preprocessing import image\n",
    "\n",
    "# Visualize IDC Negative and Positive Images Side-by-Side\n",
    "negative_images = glob.glob(f'{idc_negative_directory}/*.png')[:3]\n",
    "positive_images = glob.glob(f'{idc_positive_directory}/*.png')[:3]\n",
    "\n",
    "fig, axs = plt.subplots(3, 2, figsize=(6, 6))  # Adjusted figsize for clarity\n",
    "for neg_img, pos_img, row in zip(negative_images, positive_images, axs):\n",
    "    for img_path, ax in zip([neg_img, pos_img], row):\n",
    "        img = image.load_img(img_path)\n",
    "        img = image.img_to_array(img)\n",
    "        img /= 255.0  # Normalize image values\n",
    "        ax.imshow(img)\n",
    "        ax.axis('off')\n",
    "\n",
    "plt.suptitle(\"IDC Negative (Left) vs. Positive (Right)\")\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_sample_images(directory, title, num_images=9):\n",
    "    images = glob.glob(f\"{directory}/*.png\")\n",
    "    fig, axs = plt.subplots(3, 3, figsize=(9, 9))\n",
    "    for i, ax in enumerate(axs.flat[:min(num_images, len(images))]):\n",
    "        img = plt.imread(images[i])\n",
    "        ax.imshow(img)\n",
    "        ax.axis('off')\n",
    "    plt.suptitle(title)\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "plot_sample_images(idc_negative_directory, \"IDC Negative Samples\")\n",
    "plot_sample_images(idc_positive_directory, \"IDC Positive Samples\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_summary = pd.DataFrame({\n",
    "    \"Class\": [\"IDC Negative\", \"IDC Positive\"],\n",
    "    \"Image Count\": [idc_negative_count, idc_positive_count]\n",
    "})\n",
    "print(data_summary)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check for class imbalance\n",
    "total_images = idc_negative_count + idc_positive_count\n",
    "print(f\"Class Distribution:\\n{data_summary}\")\n",
    "print(f\"IDC Negative: {idc_negative_count / total_images:.2%}, IDC Positive: {idc_positive_count / total_images:.2%}\")\n",
    "if abs(idc_negative_count - idc_positive_count) / total_images > 0.2:\n",
    "    print(\"Warning: Potential class imbalance detected.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Prepare Image Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_datasets(training_data_path: str, image_dim: int, batch_size: int=32):\n",
    "    training_dataset = tf.keras.utils.image_dataset_from_directory(\n",
    "        training_data_path,\n",
    "        validation_split=0.2,\n",
    "        subset='training',\n",
    "        seed=315,\n",
    "        image_size=(image_dim, image_dim),\n",
    "        batch_size=batch_size,\n",
    "        color_mode='grayscale'\n",
    "    )\n",
    "    validation_dataset = tf.keras.utils.image_dataset_from_directory(\n",
    "        training_data_path,\n",
    "        validation_split=0.2,\n",
    "        subset='validation',\n",
    "        seed=315,\n",
    "        image_size=(image_dim, image_dim),\n",
    "        batch_size=batch_size,\n",
    "        color_mode='grayscale'\n",
    "    )\n",
    "    return training_dataset, validation_dataset\n",
    "\n",
    "image_dim = 50\n",
    "batch_size = 128\n",
    "training_dataset, validation_dataset = make_datasets('../data/', image_dim, batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# training_dataset = training_dataset.take(100)\n",
    "# validation_dataset = validation_dataset.take(50)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Sample Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def visualize_images(dataset, class_names):\n",
    "#     images, labels = next(iter(dataset))\n",
    "#     fig, axs = plt.subplots(3, 3, figsize=(9, 9))\n",
    "#     for i, ax in enumerate(axs.flat[:images.shape[0]]):\n",
    "#         ax.imshow(images[i].numpy().astype(\"uint8\"))\n",
    "#         ax.set_title(class_names[int(labels[i])])\n",
    "#         ax.axis('off')\n",
    "#     plt.tight_layout()\n",
    "#     plt.show()\n",
    "\n",
    "# class_names = ['IDC Negative', 'IDC Positive']\n",
    "# visualize_images(training_dataset, class_names)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "define the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Sequential([\n",
    "    layers.Conv2D(16, (3, 3), activation='relu'),\n",
    "    layers.MaxPooling2D((2, 2)),\n",
    "    layers.Conv2D(32, (3, 3), activation='relu'),\n",
    "    layers.MaxPooling2D((2, 2)),\n",
    "    layers.Flatten(),\n",
    "    layers.Dense(16, activation='relu'),\n",
    "    layers.Dropout(0.5),\n",
    "    layers.Dense(1, activation='sigmoid')\n",
    "])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Compile the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-01-29 02:27:44.030066: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'model' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[1], line 6\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[38;5;66;03m# Define the optimizer\u001b[39;00m\n\u001b[1;32m      4\u001b[0m optimizer\u001b[38;5;241m=\u001b[39mkeras\u001b[38;5;241m.\u001b[39moptimizers\u001b[38;5;241m.\u001b[39mAdam(learning_rate\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0.001\u001b[39m)\n\u001b[0;32m----> 6\u001b[0m \u001b[43mmodel\u001b[49m\u001b[38;5;241m.\u001b[39mcompile(\n\u001b[1;32m      7\u001b[0m     optimizer\u001b[38;5;241m=\u001b[39moptimizer,\n\u001b[1;32m      8\u001b[0m     loss\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mbinary_crossentropy\u001b[39m\u001b[38;5;124m'\u001b[39m,\n\u001b[1;32m      9\u001b[0m     metrics\u001b[38;5;241m=\u001b[39m[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124maccuracy\u001b[39m\u001b[38;5;124m'\u001b[39m]\n\u001b[1;32m     10\u001b[0m )\n",
      "\u001b[0;31mNameError\u001b[0m: name 'model' is not defined"
     ]
    }
   ],
   "source": [
    "from tensorflow import keras\n",
    "\n",
    "# Define the optimizer\n",
    "optimizer=keras.optimizers.Adam(learning_rate=0.001)\n",
    "\n",
    "model.compile(\n",
    "    optimizer=optimizer,\n",
    "    loss='binary_crossentropy',\n",
    "    metrics=['accuracy']\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Train the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "history = model.fit(\n",
    "    training_dataset,\n",
    "    validation_data=validation_dataset,\n",
    "    epochs=50,\n",
    "    steps_per_epoch=10,\n",
    "    validation_steps=10\n",
    ") "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Evaluate the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "loss, accuracy = model.evaluate(validation_dataset)\n",
    "print(f\"Validation Loss: {loss:.4f}, Validation Accuracy: {accuracy:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Training History"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'history' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[2], line 25\u001b[0m\n\u001b[1;32m     22\u001b[0m     plt\u001b[38;5;241m.\u001b[39mtight_layout()\n\u001b[1;32m     23\u001b[0m     plt\u001b[38;5;241m.\u001b[39mshow()\n\u001b[0;32m---> 25\u001b[0m plot_training_history(\u001b[43mhistory\u001b[49m)\n",
      "\u001b[0;31mNameError\u001b[0m: name 'history' is not defined"
     ]
    }
   ],
   "source": [
    "def plot_training_history(history):\n",
    "    plt.figure(figsize=(12, 4))\n",
    "\n",
    "    # Accuracy plot\n",
    "    plt.subplot(1, 2, 1)\n",
    "    plt.plot(history.history['accuracy'], label='Training Accuracy')\n",
    "    plt.plot(history.history['val_accuracy'], label='Validation Accuracy')\n",
    "    plt.xlabel('Epochs')\n",
    "    plt.ylabel('Accuracy')\n",
    "    plt.legend()\n",
    "    plt.title('Accuracy Over Epochs')\n",
    "\n",
    "    # Loss plot\n",
    "    plt.subplot(1, 2, 2)\n",
    "    plt.plot(history.history['loss'], label='Training Loss')\n",
    "    plt.plot(history.history['val_loss'], label='Validation Loss')\n",
    "    plt.xlabel('Epochs')\n",
    "    plt.ylabel('Loss')\n",
    "    plt.legend()\n",
    "    plt.title('Loss Over Epochs')\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "plot_training_history(history)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'model' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[3], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[43mmodel\u001b[49m\u001b[38;5;241m.\u001b[39msave(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m../data/model.keras\u001b[39m\u001b[38;5;124m'\u001b[39m)\n",
      "\u001b[0;31mNameError\u001b[0m: name 'model' is not defined"
     ]
    }
   ],
   "source": [
    "model.save('../data/model.keras')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "\n",
    "# Assume 'history' is the object returned by model.fit()\n",
    "with open('../data/history.json', 'w') as f:\n",
    "    json.dump(history.history, f)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
